{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "98aa0e3f-6b1c-4ace-bdae-b441b1a9dbf2",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import delta\n",
    "import time\n",
    "from datetime import timedelta"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "b69a9054-db7a-4046-b4a8-0c37944603cc",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "#### Setting up cosmos db connection parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "63c50458-9234-414f-8e4c-eea0a178cb3c",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "cosmos_endpoint = dbutils.secrets.get('cosmosmasterkey', 'cosmosdbendpoint')\n",
    "cosmos_masterkey = dbutils.secrets.get('cosmosmasterkey', 'cosmosmasterkey')\n",
    "cosmos_databasename = \"nasdaq-stocks-oltp\"\n",
    "cosmos_containername = \"nasdaq-stocks-rltm\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "92a371dc-e786-4c4e-a9f6-75d6e0733f2e",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "#### Initial extraction of delta table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "89ebe128-d21e-41ae-9b2b-fd04738cb2df",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# cosmos_read_config = {\n",
    "#   \"spark.cosmos.accountEndpoint\": cosmos_endpoint,\n",
    "#   \"spark.cosmos.accountKey\": cosmos_masterkey,\n",
    "#   \"spark.cosmos.database\": cosmos_databasename,\n",
    "#   \"spark.cosmos.container\": cosmos_containername,\n",
    "#   \"spark.cosmos.read.inferSchema.enabled\" : \"true\",\n",
    "#   \"spark.cosmos.write.strategy\": \"ItemOverwrite\"\n",
    "# }\n",
    "\n",
    "# cosmos_df = spark.read.format(\"cosmos.oltp\").options(**cosmos_read_config).load()\n",
    "# cosmos_df.write.mode(\"overwrite\").saveAsTable(\"STOCK_PULL\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "e9cc0207-2d34-468a-815c-a979cd29f841",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "#### Run/Merge Change Feed Into Delta Table "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "bbfcdb40-7f36-4154-aedf-a6d6bdda0d48",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "#using creation timestamp to consider for starting point of change data feed\n",
    "#spark streaming will control checkpoint automatically and will only request changes since last extraction timestamp\n",
    "table_creation_timestmap = (delta.DeltaTable.forName(spark,\"STOCK_PULL\").history().collect()[0][\"timestamp\"] - timedelta(hours=1)).isoformat() + \"Z\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "27a14e85-949f-4265-91cd-222f0c9339c2",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "waiting for trigger once to finish\nwaiting for trigger once to finish\nwaiting for trigger once to finish\nwaiting for trigger once to finish\n70 rows read\n"
     ]
    }
   ],
   "source": [
    "cosmos_change_feed_config = {\n",
    "  \"spark.cosmos.accountEndpoint\": cosmos_endpoint,\n",
    "  \"spark.cosmos.accountKey\": cosmos_masterkey,\n",
    "  \"spark.cosmos.database\": cosmos_databasename,\n",
    "  \"spark.cosmos.container\": cosmos_containername,\n",
    "  \"spark.cosmos.read.partitioning.strategy\": \"Default\",\n",
    "  \"spark.cosmos.read.inferSchema.enabled\" : \"true\",\n",
    "  \"spark.cosmos.changeFeed.startFrom\" : table_creation_timestmap,\n",
    "  \"spark.cosmos.changeFeed.mode\" : \"Incremental\",\n",
    "}\n",
    "\n",
    "df_change_feed = (\n",
    "  spark\n",
    "  .readStream\n",
    "  .format(\"cosmos.oltp.changeFeed\")\n",
    "  .options(**cosmos_change_feed_config)\n",
    "  .load()\n",
    ")\n",
    "\n",
    "def merge_delta(incremental, target): \n",
    "  incremental.createOrReplaceTempView(\"incremental\")\n",
    "  \n",
    "  incremental._jdf.sparkSession().sql(f\"\"\"\n",
    "    MERGE INTO {target} tgt\n",
    "    USING incremental i\n",
    "    ON (i.StRecievdTimeStamp=tgt.StRecievdTimeStamp AND i.ticker = tgt.ticker)\n",
    "    WHEN MATCHED THEN UPDATE SET *\n",
    "    WHEN NOT MATCHED THEN INSERT *\n",
    "  \"\"\")\n",
    " \n",
    "streaming_output = (\n",
    "  df_change_feed\n",
    "  .writeStream\n",
    "  .trigger(availableNow=True) #it can be changed to run in streaming mode instead of batch\n",
    "  .format('delta')\n",
    "  .outputMode(\"update\")\n",
    "  .option(\"checkpointLocation\", \"/cosmos/checkpoint_changefeed_stocks_table\")\n",
    "  .foreachBatch(lambda i, b: merge_delta(i, \"STOCK_PULL\"))\n",
    "  .start()\n",
    ")\n",
    "\n",
    "for s in spark.streams.active:\n",
    "  while s.isActive:\n",
    "    print('waiting for trigger once to finish')\n",
    "    time.sleep(1)\n",
    "    \n",
    "if streaming_output.lastProgress:\n",
    "  print(f\"{streaming_output.lastProgress['numInputRows']} rows read\")\n",
    "else:\n",
    "  print(\"no changes in cosmos since last execution\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "cba1dc97-2060-4e37-8577-2eb9689ac4d8",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "dashboards": [],
   "language": "python",
   "notebookMetadata": {
    "mostRecentlyExecutedCommandWithImplicitDF": {
     "commandId": 1070723551778397,
     "dataframes": [
      "_sqldf"
     ]
    },
    "pythonIndentUnit": 4
   },
   "notebookName": "Nasdaq-stocks-rltm-ingest",
   "widgets": {}
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
